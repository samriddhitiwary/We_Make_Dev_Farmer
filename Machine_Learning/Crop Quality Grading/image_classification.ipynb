{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d4e98b",
   "metadata": {},
   "source": [
    "# Image Classification with TensorFlow\n",
    "This notebook demonstrates training an image classification model using TensorFlow on CPU, saving/loading the model, and running inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7158645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow if not already installed\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ImportError:\n",
    "    !pip install tensorflow\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2e3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ec60d",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Images should be organized in subfolders under `datasets/images`, one folder per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d09341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15628 files belonging to 3 classes.\n",
      "Found 3898 files belonging to 3 classes.\n",
      "Classes: ['Bad Quality_Fruits', 'Good Quality_Fruits', 'Mixed Qualit_Fruits']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dir = r\"C:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\Crop Quality Grading\\train\"\n",
    "test_dir = r\"C:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\Crop Quality Grading\\test\"\n",
    "\n",
    "img_height, img_width = 180, 180\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a46db",
   "metadata": {},
   "source": [
    "## Visualize Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30cc7b",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb8dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Conv2D(512, 3, activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494beb16",
   "metadata": {},
   "source": [
    "## Train the Model (on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96fe8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.7337 - loss: 0.6079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 647ms/step - accuracy: 0.8136 - loss: 0.4545 - val_accuracy: 0.9020 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - accuracy: 0.9000 - loss: 0.2780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 857ms/step - accuracy: 0.9137 - loss: 0.2335 - val_accuracy: 0.9189 - val_loss: 0.2055\n",
      "Epoch 3/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9289 - loss: 0.1925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 1s/step - accuracy: 0.9420 - loss: 0.1559 - val_accuracy: 0.9577 - val_loss: 0.1172\n",
      "Epoch 4/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 556ms/step - accuracy: 0.9607 - loss: 0.1083 - val_accuracy: 0.9297 - val_loss: 0.2165\n",
      "Epoch 5/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 619ms/step - accuracy: 0.9719 - loss: 0.0740 - val_accuracy: 0.9418 - val_loss: 0.1868\n",
      "Epoch 6/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9755 - loss: 0.0668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 591ms/step - accuracy: 0.9804 - loss: 0.0539 - val_accuracy: 0.9695 - val_loss: 0.1103\n",
      "Epoch 7/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 564ms/step - accuracy: 0.9866 - loss: 0.0394 - val_accuracy: 0.9659 - val_loss: 0.1304\n",
      "Epoch 8/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1857s\u001b[0m 4s/step - accuracy: 0.9915 - loss: 0.0237 - val_accuracy: 0.9710 - val_loss: 0.1263\n",
      "Epoch 9/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 984ms/step - accuracy: 0.9880 - loss: 0.0354 - val_accuracy: 0.9728 - val_loss: 0.1185\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force TensorFlow to use CPU\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=3,          # Stop after 3 epochs of no improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',     # File to save the best model\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stop, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea266a",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63e7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9aa153",
   "metadata": {},
   "source": [
    "## Inference on a New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f37d0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Predicted class for the fruits are: Bad Quality_Fruits (83.51% confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predicted class for the fruits are: Good Quality_Fruits (88.32% confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Predicted class for the fruits are: Mixed Qualit_Fruits (99.89% confidence)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "img_height, img_width = 180, 180\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    predicted_class = class_names[np.argmax(score)]\n",
    "    confidence = 100 * np.max(score)\n",
    "    print(f\"Predicted class for the fruits are: {predicted_class} ({confidence:.2f}% confidence)\")\n",
    "    return predicted_class, confidence\n",
    "\n",
    "test_image_paths = [\n",
    "    r\"C:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\Crop Quality Grading\\test\\Bad Quality_Fruits\\Lime_Bad\\Lime_Bad_176.jpg\",\n",
    "    r\"C:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\Crop Quality Grading\\test\\Good Quality_Fruits\\Orange_Good\\Orange_Good_27.jpg\",\n",
    "    r\"C:\\Users\\samri\\cod\\git\\Farmer\\Machine_Learning\\Crop Quality Grading\\test\\Mixed Qualit_Fruits\\Banana\\Banana_2.jpg\"\n",
    "]\n",
    "\n",
    "for img_path in test_image_paths:\n",
    "    predict_image(img_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
